{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO \n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 320x640 5 persons, 91.7ms\n",
      "Speed: 2.5ms preprocess, 91.7ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 81.9ms\n",
      "Speed: 3.0ms preprocess, 81.9ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 73.8ms\n",
      "Speed: 2.3ms preprocess, 73.8ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 72.3ms\n",
      "Speed: 2.9ms preprocess, 72.3ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 72.1ms\n",
      "Speed: 2.9ms preprocess, 72.1ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 84.9ms\n",
      "Speed: 4.0ms preprocess, 84.9ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 70.8ms\n",
      "Speed: 3.1ms preprocess, 70.8ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 71.0ms\n",
      "Speed: 1.9ms preprocess, 71.0ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 65.3ms\n",
      "Speed: 2.3ms preprocess, 65.3ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 71.6ms\n",
      "Speed: 2.4ms preprocess, 71.6ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 73.9ms\n",
      "Speed: 2.4ms preprocess, 73.9ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 68.6ms\n",
      "Speed: 3.3ms preprocess, 68.6ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 1 backpack, 67.9ms\n",
      "Speed: 1.8ms preprocess, 67.9ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 1 backpack, 74.0ms\n",
      "Speed: 2.3ms preprocess, 74.0ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 1 car, 1 backpack, 58.8ms\n",
      "Speed: 2.0ms preprocess, 58.8ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 1 car, 1 backpack, 55.8ms\n",
      "Speed: 2.0ms preprocess, 55.8ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 1 car, 1 backpack, 58.2ms\n",
      "Speed: 1.5ms preprocess, 58.2ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 1 car, 1 backpack, 54.6ms\n",
      "Speed: 2.1ms preprocess, 54.6ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 1 car, 55.4ms\n",
      "Speed: 1.6ms preprocess, 55.4ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 1 car, 1 backpack, 51.5ms\n",
      "Speed: 1.6ms preprocess, 51.5ms inference, 0.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 1 car, 52.3ms\n",
      "Speed: 1.8ms preprocess, 52.3ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 1 car, 1 truck, 52.6ms\n",
      "Speed: 2.1ms preprocess, 52.6ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 1 car, 1 truck, 71.0ms\n",
      "Speed: 1.6ms preprocess, 71.0ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 1 car, 61.5ms\n",
      "Speed: 1.6ms preprocess, 61.5ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 1 car, 68.8ms\n",
      "Speed: 2.0ms preprocess, 68.8ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 1 car, 70.6ms\n",
      "Speed: 2.2ms preprocess, 70.6ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 1 car, 57.5ms\n",
      "Speed: 2.7ms preprocess, 57.5ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 1 truck, 51.1ms\n",
      "Speed: 1.7ms preprocess, 51.1ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 1 truck, 54.4ms\n",
      "Speed: 1.8ms preprocess, 54.4ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 1 car, 1 truck, 57.6ms\n",
      "Speed: 1.7ms preprocess, 57.6ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 53.7ms\n",
      "Speed: 1.8ms preprocess, 53.7ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 1 truck, 48.4ms\n",
      "Speed: 1.7ms preprocess, 48.4ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 1 truck, 48.2ms\n",
      "Speed: 1.6ms preprocess, 48.2ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 1 truck, 50.4ms\n",
      "Speed: 1.6ms preprocess, 50.4ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 1 truck, 51.3ms\n",
      "Speed: 2.3ms preprocess, 51.3ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 1 truck, 57.5ms\n",
      "Speed: 1.9ms preprocess, 57.5ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 1 truck, 61.7ms\n",
      "Speed: 3.5ms preprocess, 61.7ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 1 truck, 66.4ms\n",
      "Speed: 2.3ms preprocess, 66.4ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 1 truck, 68.6ms\n",
      "Speed: 2.7ms preprocess, 68.6ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 71.6ms\n",
      "Speed: 2.7ms preprocess, 71.6ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 70.6ms\n",
      "Speed: 4.2ms preprocess, 70.6ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 70.7ms\n",
      "Speed: 2.9ms preprocess, 70.7ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 73.6ms\n",
      "Speed: 3.0ms preprocess, 73.6ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 81.5ms\n",
      "Speed: 3.5ms preprocess, 81.5ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n"
     ]
    }
   ],
   "source": [
    "#Person detection using YOLOv8 Nano\n",
    "\n",
    "model = YOLO('yolov8n.pt')  # Load pretrained YOLOv8 Nano model\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(\"C:\\\\WoSAAP\\\\Voilence Against Woman DATASET\\\\WhatsApp Video 2025-02-16 at 20.29.05_0087f775.mp4\")  \n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if success:\n",
    "        results = model(frame, stream=True,conf=0.4) # Run YOLOv8 inference on the frame\n",
    "        for r in results: # iterate through each result\n",
    "            annotated_frame = r.plot()  # plot and get the annotated frame\n",
    "            cv2.imshow(\"YOLOv8 Inference\", annotated_frame)  # Display the annotated frame\n",
    "   \n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):  # Break the loop if 'q' is pressed\n",
    "                break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()  # Release the video capture object\n",
    "cv2.destroyAllWindows()  # Close the display window"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
